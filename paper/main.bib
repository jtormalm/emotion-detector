@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})



@misc{Authors14,
 author = {FirstName LastName},
 title = {The frobnicatable foo filter},
 note = {Face and Gesture submission ID 324. Supplied as supplemental material {\tt fg324.pdf}},
 year = 2014
}

@misc{Authors14b,
 author = {FirstName LastName},
 title = {Frobnication tutorial},
 note = {Supplied as supplemental material {\tt tr.pdf}},
 year = 2014
}

@article{Alpher02,
author = {FirstName Alpher},
title = {Frobnication},
journal = PAMI,
volume = 12,
number = 1,
pages = {234--778},
year = 2002
}

@article{Alpher03,
author = {FirstName Alpher and  FirstName Fotheringham-Smythe},
title = {Frobnication revisited},
journal = {Journal of Foo},
volume = 13,
number = 1,
pages = {234--778},
year = 2003
}

@article{Alpher04,
author = {FirstName Alpher and FirstName Fotheringham-Smythe and FirstName Gamow},
title = {Can a machine frobnicate?},
journal = {Journal of Foo},
volume = 14,
number = 1,
pages = {234--778},
year = 2004
}

@inproceedings{Alpher05,
author = {FirstName Alpher and FirstName Gamow},
title = {Can a computer frobnicate?},
booktitle = CVPR,
pages = {234--778},
year = 2005
}


@inproceedings{goodfellow2013challenges,
  title={Challenges in representation learning: A report on three machine learning contests},
  author={Goodfellow, Ian J and Erhan, Dumitru and Carrier, Pierre Luc and Courville, Aaron and Mirza, Mehdi and Hamner, Ben and Cukierski, Will and Tang, Yichuan and Thaler, David and Lee, Dong-Hyun and others},
  booktitle={International Conference on Neural Information Processing Systems (ICONIP)},
  year={2013}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{lideng2020survey,
  title={Deep facial expression recognition: A survey},
  author={Li, Shan and Deng, Weihong},
  journal={IEEE transactions on affective computing},
  volume={13},
  number={2},
  pages={1195--1215},
  year={2020},
  publisher={IEEE}
}

@inproceedings{viola2001rapid,
  title={Rapid object detection using a boosted cascade of simple features},
  author={Viola, Paul and Jones, Michael},
  booktitle={Proceedings of the 2001 IEEE computer society conference on computer vision and pattern recognition. CVPR 2001},
  volume={1},
  pages={I--I},
  year={2001},
  organization={IEEE}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@inproceedings{selvaraju2017grad,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{Ramzan2020,
  author    = {Fawad Ramzan and
               Muhammad Usman Ghani Khan and
               Amjad Rehmat and
               et al.},
  title     = {A Deep Learning Approach for Automated Diagnosis and Multi-Class Classification of Alzheimer’s Disease Stages Using Resting-State fMRI and Residual Neural Networks},
  journal   = {Journal of Medical Systems},
  volume    = {44},
  number    = {2},
  pages     = {37},
  year      = {2020},
  doi       = {10.1007/s10916-019-1475-2},
  url       = {https://doi.org/10.1007/s10916-019-1475-2},
  note      = {Received 05 July 2019, Accepted 11 October 2019, Published 18 December 2019}
}


@article{He2015,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {arXiv preprint arXiv:1512.03385},
  year      = {2015},
  url       = {https://doi.org/10.48550/arXiv.1512.03385},
  note      = {Tech report, submitted 10 Dec 2015}
}


@inproceedings{Wang2017ResidualAttention,
  author    = {F. Wang and M. Jiang and C. Qian and S. Yang and C. Li and H. Zhang and X. Wang and X. Tang},
  title     = {Residual Attention Network for Image Classification},
  booktitle = {CVPR},
  year      = {2017},
  doi       = {10.1109/CVPR.2017.367}
}

@inproceedings{Jaderberg2015SpatialTransformer,
  author    = {M. Jaderberg and K. Simonyan and A. Zisserman and K. Kavukcuoglu},
  title     = {Spatial Transformer Networks},
  booktitle = {NeurIPS},
  year      = {2015},
  url       = {https://arxiv.org/abs/1506.02025}
}

@article{Dosovitskiy2021ViT,
  author  = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner and Mostafa Dehghani and Matthias Minderer and Georg Heigold and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  title   = {An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  journal = {ICLR},
  year    = {2021},
  url     = {https://arxiv.org/abs/2010.11929},
  doi     = {10.48550/arXiv.2010.11929}
}

@article{Zhang2021TransFER,
  author  = {X. Zhang and L. Wang and X. Gao},
  title   = {TransFER: Transformer-based Facial Expression Recognition},
  journal = {arXiv preprint arXiv:2103.16760},
  year    = {2021},
  url     = {https://arxiv.org/abs/2103.16760}
}

@article{Zhao2016DeepFER,
  author  = {G. Zhao and M. Pietikäinen},
  title   = {Learning Deep Facial Expression Features from Video Sequences},
  journal = {IEEE Transactions on Image Processing},
  year    = {2016},
  volume  = {25},
  number  = {1},
  pages   = {883-897},
  doi     = {10.1109/TIP.2015.2493738}
}

@article{Li2018SurveyFER,
  author  = {S. Li and W. Deng},
  title   = {Deep Facial Expression Recognition: A Survey},
  journal = {IEEE Transactions on Affective Computing},
  year    = {2018},
  volume  = {10},
  number  = {1},
  pages   = {3-24},
  doi     = {10.1109/TAFFC.2017.2740929}
}

@inproceedings{Viola2001HaarCascade,
  author    = {P. Viola and M. Jones},
  title     = {Rapid Object Detection using a Boosted Cascade of Simple Features},
  booktitle = {CVPR},
  year      = {2001},
  doi       = {10.1109/CVPR.2001.990517}
}

@article{Zhang2016MTCNN,
  author  = {K. Zhang and Z. Zhang and Z. Li and Y. Qiao},
  title   = {Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks},
  journal = {IEEE Transactions on Image Processing},
  year    = {2016},
  volume  = {25},
  number  = {11},
  pages   = {  5653-5666},
  doi     = {10.1109/TIP.2016.2603342}
}

@inproceedings{Zhang2017FaceBoxes,
  author    = {S. Zhang and X. Zhu and Z. Lei and H. Shi and X. Wang and S. Z. Li},
  title     = {FaceBoxes: A CPU Real-time Face Detector with High Accuracy},
  booktitle = {ICIP},
  year      = {2017},
  doi       = {10.1109/ICIP.2017.8296716}
}

@inproceedings{Yun2019CutMix,
  author    = {Sangdoo Yun and Dongyoon Han and Seong Joon Oh and Sanghyuk Chun and Junsuk Choe and Youngjoon Yoo},
  title     = {CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features},
  booktitle = {ICCV},
  year      = {2019},
  doi       = {10.1109/ICCV.2019.00457}
}

@inproceedings{Zhang2018Mixup,
  author    = {Hongyi Zhang and Moustapha Cisse and Yann N. Dauphin and David Lopez-Paz},
  title     = {mixup: Beyond Empirical Risk Minimization},
  booktitle = {ICLR},
  year      = {2018},
  url       = {https://arxiv.org/abs/1710.09412}
}

@article{Liu2020MultiTaskFER,
  author  = {L. Liu and H. Zhang and J. Yin},
  title   = {Multi-Task Learning for Facial Expression Recognition with Data Augmentation},
  journal = {Pattern Recognition Letters},
  year    = {2020},
  volume  = {133},
  pages   = {305-311},
  doi     = {10.1016/j.patrec.2020.02.022}
}

@inproceedings{Wang2020ECANet,
  author  = {Qilong Wang and Banggu Wu and Pengfei Zhu and Peihua Li and Wangmeng Zuo and Lei Zhang},
  title   = {ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks},
  booktitle = {CVPR},
  year    = {2020},
  doi     = {10.1109/CVPR42600.2020.00831}
}

@article{Mehta2021MobileViT,
  author  = {Shivam Mehta and Mitesh M. Khapra and Partha Talukdar},
  title   = {MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer},
  journal = {arXiv preprint arXiv:2110.02178},
  year    = {2021},
  url     = {https://arxiv.org/abs/2110.02178}
}

@article{Baltrusaitis2018Multimodal,
  author  = {Tadas Baltrušaitis and Chaitanya Ahuja and Louis-Philippe Morency},
  title   = {Multimodal Machine Learning: A Survey and Taxonomy},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2018},
  volume  = {41},
  number  = {2},
  pages   = {423-443},
  doi     = {10.1109/TPAMI.2018.2798607}
}

@article{Zeng2020AudioVisual,
  author  = {Jinxiu Zeng and Shun Zhang and Guoying Zhao},
  title   = {Audio-Visual Emotion Recognition with Deep Learning: A Survey},
  journal = {arXiv preprint arXiv:2005.05595},
  year    = {2020},
  url     = {https://arxiv.org/abs/2005.05595}
}

@inproceedings{Han2016DeepCompression,
  author    = {Song Han and Huizi Mao and William J. Dally},
  title     = {Deep Compression: Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman Coding},
  booktitle = {ICLR},
  year      = {2016},
  url       = {https://arxiv.org/abs/1510.00149}
}

@inproceedings{Jacob2018Quantization,
  author    = {Benoit Jacob and Skirmantas Kligys and Bo Chen and Menglong Zhu and Matthew Tang and Andrew Howard and Hartwig Adam and Dmitry Kalenichenko},
  title     = {Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference},
  booktitle = {CVPR},
  year      = {2018},
  doi       = {10.1109/CVPR.2018.00444}
}
